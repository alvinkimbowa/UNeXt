import argparse
import os
from glob import glob

import cv2
import torch
import torch.backends.cudnn as cudnn
import yaml
from albumentations.augmentations import transforms
from albumentations.core.composition import Compose
from sklearn.model_selection import train_test_split
from tqdm import tqdm

import archs
from dataset import nnUNetDataset
from metrics import iou_score
from utils import AverageMeter
from albumentations import RandomRotate90,Resize
import time
from archs import UNext


def parse_args():
    parser = argparse.ArgumentParser()

    parser.add_argument('--name', default=None,
                        help='model name')
    parser.add_argument('--train_dataset', default='Dataset073_GE_LE',
                        help='train dataset name')
    parser.add_argument('--train_fold', type=int, required=True,
                        help='train fold index (0-4) or "all" to combine all folds')
    parser.add_argument('--test_dataset', type=str, required=True,
                        help='test dataset name')
    parser.add_argument('--test_split', type=str, required=True,
                        help='test split (Ts or Te)')

    args = parser.parse_args()

    return args


def main():
    args = parse_args()

    model_dir = f"models/{args.train_dataset}/fold_{args.train_fold}"
    with open(f'{model_dir}/config.yml', 'r') as f:
        config = yaml.load(f, Loader=yaml.FullLoader)

    print('-'*20)
    for key in config.keys():
        print('%s: %s' % (key, str(config[key])))
    print('-'*20)

    cudnn.benchmark = True

    print("=> creating model %s" % config['arch'])
    model = archs.__dict__[config['arch']](config['num_classes'],
                                           config['input_channels'],
                                           config['deep_supervision'])

    model = model.cuda()

    model.load_state_dict(torch.load(os.path.join(model_dir, 'model.pth')))
    model.eval()

    val_transform = Compose([
        Resize(config['input_h'], config['input_w']),
        transforms.Normalize(),
    ])

    if args.test_dataset == args.train_dataset:
        assert args.train_fold != 'all', "TODO: Implement validation for all folds"
        val_dataset = nnUNetDataset(
            dataset_name=args.test_dataset,
            split=args.test_split,
            fold=args.train_fold,
            split_type='val',
            transform=val_transform,
            eval=False)
    else:
        val_dataset = nnUNetDataset(
            dataset_name=args.test_dataset,
            split=args.test_split,
            transform=val_transform,
            eval=True)
    val_loader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers'],
        drop_last=False)

    iou_avg_meter = AverageMeter()
    dice_avg_meter = AverageMeter()
    gput = AverageMeter()
    cput = AverageMeter()

    save_dir = os.path.join(model_dir, 'test', args.test_dataset, 'preds')
    os.makedirs(save_dir, exist_ok=True)
    with torch.no_grad():
        for input, target, meta in tqdm(val_loader, total=len(val_loader)):
            input = input.cuda()
            target = target.cuda()
            model = model.cuda()
            # compute output
            output = model(input)


            iou,dice = iou_score(output, target)
            iou_avg_meter.update(iou, input.size(0))
            dice_avg_meter.update(dice, input.size(0))

            output = torch.sigmoid(output).cpu().numpy()
            output[output>=0.5]=1
            output[output<0.5]=0

            for i in range(len(output)):
                for c in range(config['num_classes']):
                    cv2.imwrite(os.path.join(save_dir, meta['img_id'][i] + '.png'),
                            (output[i, c] * 255).astype('uint8'))

    print('IoU: %.4f' % iou_avg_meter.avg)
    print('Dice: %.4f' % dice_avg_meter.avg)

    torch.cuda.empty_cache()


if __name__ == '__main__':
    main()
